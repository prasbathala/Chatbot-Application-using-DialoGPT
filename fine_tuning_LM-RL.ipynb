{"cells":[{"cell_type":"markdown","metadata":{"id":"AU64cjxVwUcf"},"source":["# Generating Text in Chatbots"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RIt9bskLwUcg","executionInfo":{"status":"ok","timestamp":1682297995916,"user_tz":240,"elapsed":30646,"user":{"displayName":"Prasanth Bathala","userId":"17979581191317044000"}},"outputId":"7731f61e-9c90-4bdf-95da-c2ec82452715"},"outputs":[{"output_type":"stream","name":"stdout","text":["Installing the following packages: {'trl', 'transformers'}\n"]}],"source":["import sys\n","import subprocess\n","import pkg_resources\n","\n","# Find out which packages are missing.\n","installed_packages = {dist.key for dist in pkg_resources.working_set}\n","required_packages = {'torch', 'transformers', 'trl'}\n","missing_packages = required_packages - installed_packages\n","\n","# If there are missing packages install them.\n","if missing_packages:\n","    print('Installing the following packages: ' + str(missing_packages))\n","    python = sys.executable\n","    subprocess.check_call([python, '-m', 'pip', 'install', *missing_packages], stdout=subprocess.DEVNULL)"]},{"cell_type":"markdown","metadata":{"id":"lr19DsD0wUcg"},"source":["## Fine-tuning the pre-trained model using reinforcement learning"]},{"cell_type":"markdown","metadata":{"id":"S2mHKE_2wUcg"},"source":["We utilize the `Transformer Reinforcement Learning` (trl) library that allows the training of transformer language models with `Proximal Policy Optimization` (PPO). \n","\n","The small version of the _DialoGPT_ model is used."]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":232},"id":"8XcZilYAwUcg","executionInfo":{"status":"error","timestamp":1682298300164,"user_tz":240,"elapsed":11610,"user":{"displayName":"Prasanth Bathala","userId":"17979581191317044000"}},"outputId":"77e258eb-dfbb-4015-bc6e-a2fbac95111a"},"outputs":[{"output_type":"display_data","data":{"text/plain":["\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/IPython/core/\u001b[0m\u001b[1;33minteractiveshell.py\u001b[0m:\u001b[94m3553\u001b[0m in \u001b[92mrun_code\u001b[0m         \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m3550 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94melif\u001b[0m async_ :                                                             \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m3551 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[94mawait\u001b[0m \u001b[96meval\u001b[0m(code_obj, \u001b[96mself\u001b[0m.user_global_ns, \u001b[96mself\u001b[0m.user_ns)               \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m3552 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                     \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m3553 \u001b[2m│   │   │   │   │   \u001b[0mexec(code_obj, \u001b[96mself\u001b[0m.user_global_ns, \u001b[96mself\u001b[0m.user_ns)                     \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m3554 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mfinally\u001b[0m:                                                                      \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m3555 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[2m# Reset our crash handler in place\u001b[0m                                        \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m3556 \u001b[0m\u001b[2m│   │   │   │   \u001b[0msys.excepthook = old_excepthook                                           \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m in \u001b[92m<cell line: 3>\u001b[0m:\u001b[94m3\u001b[0m                                                                              \u001b[31m│\u001b[0m\n","\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n","\u001b[1;91mModuleNotFoundError: \u001b[0mNo module named \u001b[32m'trl.gpt2'\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.9/dist-packages/IPython/core/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">interactiveshell.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3553</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">run_code</span>         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3550 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">elif</span> async_ :                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3551 │   │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">await</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">eval</span>(code_obj, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.user_global_ns, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.user_ns)               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3552 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>3553 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>exec(code_obj, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.user_global_ns, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.user_ns)                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3554 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">finally</span>:                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3555 │   │   │   │   # Reset our crash handler in place</span>                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3556 │   │   │   │   </span>sys.excepthook = old_excepthook                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;cell line: 3&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3</span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n","<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">ModuleNotFoundError: </span>No module named <span style=\"color: #008000; text-decoration-color: #008000\">'trl.gpt2'</span>\n","</pre>\n"]},"metadata":{}}],"source":["import torch\n","from transformers import GPT2Tokenizer\n","from trl.gpt2 import GPT2HeadWithValueModel, respond_to_batch\n","from trl.ppo import PPOTrainer\n","\n","# Load the models.\n","gpt2_model = GPT2HeadWithValueModel.from_pretrained('microsoft/DialoGPT-small')\n","gpt2_model_ref = GPT2HeadWithValueModel.from_pretrained('microsoft/DialoGPT-small')\n","gpt2_tokenizer = GPT2Tokenizer.from_pretrained('microsoft/DialoGPT-small')"]},{"cell_type":"markdown","metadata":{"id":"YgTImQ9YwUch"},"source":["Next we create the _chat_ method."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JfWZGL0ZwUch"},"outputs":[],"source":["# Chat with the bot using a new input and the previous history.\n","def chat(input, history=[], gen_kwargs=[]):\n","    \n","    # Tokenize the input.\n","    new_user_input_ids = gpt2_tokenizer.encode(input+gpt2_tokenizer.eos_token, return_tensors='pt')\n","\n","    # Update the dialogue history.\n","    bot_input_ids = torch.cat([torch.LongTensor(history), new_user_input_ids], dim=-1)\n","\n","    # Generate the response of the bot.\n","    new_history = gpt2_model.generate(bot_input_ids, **gen_kwargs).tolist()\n","\n","    # Convert the tokens to text.\n","    output = gpt2_tokenizer.decode(new_history[0]).split(\"<|endoftext|>\")\n","    output = [(output[i], output[i+1]) for i in range(0, len(output)-1, 2)]\n","    return output, new_history"]},{"cell_type":"markdown","metadata":{"id":"HQtQIpggwUch"},"source":["We can then define the parameters for the model and initializat the trainer."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DFjwBRSbwUch"},"outputs":[],"source":["# Parameters for the model.\n","gen_kwargs = {\n","    \"max_length\":1000,\n","    \"min_length\":-1,\n","    \"top_k\": 0.0,\n","    \"top_p\": 1.0,\n","    \"do_sample\": True,\n","    \"pad_token_id\": gpt2_tokenizer.eos_token_id\n","}\n","\n","# Initialize the trainer.\n","ppo_config = {'batch_size': 1, 'forward_batch_size': 1}\n","ppo_trainer = PPOTrainer(gpt2_model, gpt2_model_ref, gpt2_tokenizer, **ppo_config)"]},{"cell_type":"markdown","metadata":{"id":"EDg2HfkGwUch"},"source":["The query is one of the elements for the reinforcement learning."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5WJaKUDTwUch"},"outputs":[],"source":["# Encode a query.\n","query_txt = \"Does money buy happiness?\"\n","query_tensor = gpt2_tokenizer.encode(query_txt+gpt2_tokenizer.eos_token, return_tensors=\"pt\")"]},{"cell_type":"markdown","metadata":{"id":"9XjrG_Y2wUch"},"source":["Let's perform ten tnteraction that will help tuning the language model. In practice many more interactions are needed."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wlh6FgEVwUch","outputId":"ab99007c-28a4-4f28-92cc-26c65203ad84"},"outputs":[{"name":"stdout","output_type":"stream","text":["- reward: If you keep barney top 10, idk if it's even cheaper\n","+ reward: Yes, but before there was always spend money how can you get happiness. Get happiness, get your money for it.\n","- reward: Megan convinces Barbel that the advice she was giving was good. In retrospect, they were the right choices.\n","+ reward: Money buys happiness.\n","+ reward: Money buy happiness?\n","+ reward: . can i buy happiness from your family?\n","+ reward: Money buys happiness. Money buys happiness. Money doesn't buy happiness. What trends should we look to bring with our little robot uprising? Money Is Happiness.\n","+ reward: money buy happiness religion wage happiness\n","+ reward: Money buy happiness. Any number guys... anyone? Please?\n","- reward: Why would you come live with someone else when you can have this mother?\n"]}],"source":["# Repeat the training for 10 interactions.\n","for x in range(10):\n","\n","    response_tensors = []\n","    pipe_outputs = []\n","\n","    # Get a reposnse from the chatbot.\n","    result, history = chat(query_txt, [], gen_kwargs)\n","    response_txt = result[0][1]\n","    response_tensor = gpt2_tokenizer.encode(response_txt+gpt2_tokenizer.eos_token, return_tensors=\"pt\")\n","    \n","    # Positive reward.\n","    if response_txt.find('happy') >= 0 or response_txt.find('happiness') >= 0 or response_txt.find('fun') >= 0:\n","        print(\"+ reward: \" + response_txt)\n","        reward = [torch.tensor(1.0)]\n","    # Negative reward.\n","    else:\n","        print(\"- reward: \" + response_txt)\n","        reward = [torch.tensor(-1.0)]\n","\n","    # Train the model with the ppo algorithm.\n","    train_stats = ppo_trainer.step([query_tensor[0]], [response_tensor[0]], reward)"]},{"cell_type":"markdown","metadata":{"id":"-zWUxk_RwUch"},"source":["## What we have learned …\n","\n","| |\n","| --- |\n","| **ML concepts** <ul><li>Fine-tuning</li><li>Reinforcement learning</li></ul> |\n","| |"]}],"metadata":{"kernelspec":{"display_name":"Python 3.9.7 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"metadata":{"interpreter":{"hash":"34c3ec88db1a123a786d67d086f3ede88281b71e687e4350202a680e0c5fcbcd"}},"vscode":{"interpreter":{"hash":"8f1e200aa4e9598f1b1017d8bb6526388dc3fae44f5def43455ba665e800f8e8"}},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}